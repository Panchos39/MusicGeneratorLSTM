{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1t9WYnN2Fa60"
   },
   "source": [
    "# CSE 204 Lab 8: Classification of the CIFAR-10 dataset using CNNs\n",
    "\n",
    "J.B. Scoggins\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jbscoggi/teaching/blob/master/Polytechnique/CSE204/Lab8.ipynb) \n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jbscoggi/teaching/master?filepath=Polytechnique%2FCSE204%2FLab8.ipynb)\n",
    "\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) provides 60000 32x32-pixel images, classified into 10 categories.  The figure below provides a random sample of some images in each category.\n",
    "\n",
    "![](https://github.com/jbscoggi/teaching/blob/master/Polytechnique/CSE204/artwork/cifar_images.png?raw=1)\n",
    "\n",
    "During this session, you will learn how to build a Convolutional Neural Network (CNN), which (when trained) will be able to automatically classify new images into one of these categories.  We will make use of the [Keras library](https://www.tensorflow.org/guide/keras) which provides a high-level interface to TensorFlow, which you have already seen.\n",
    "\n",
    "## Introduction to Keras\n",
    "\n",
    "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
    "\n",
    "- __User friendly__: Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
    "- __Modular and composable__: Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
    "- __Easy to extend__: Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n",
    "\n",
    "In Keras, models are built by assymbling multiple layers.  Suppose we want to create a new multilayer perceptron model to categorize 128-feature data into 10 labeled categories.  The Keras code could look like:\n",
    "\n",
    "```python\n",
    "# Create a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model\n",
    "model.add(layers.Dense(64, activation='relu'), input_shape=[128])\n",
    "# Add another\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "# Add a softmax layer with 10 output units\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "The `input_shape` argument must be given for the first layer in the model, however all other layers will automatically determine the input shape based on the previous layer in the model.  Note that the code above is substantially simpler than the corresponding TensorFlow code.  This is particular useful for building convolutional or other types of layers, as we will see.\n",
    "\n",
    "Once built, a model's learning can be configured with the `compile()` function\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=tf.train.AdamOptimizer(0.001), \n",
    "    metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "In this case, a cross-entropy loss function is used with the ADAM optimization algorithm.  The `metrics` argument allows the model to keep track of a number of [training metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) during training.\n",
    "\n",
    "Once configured, training is performed using the `fit()` function.\n",
    "\n",
    "```python\n",
    "model.fit(data, labels, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "The function takes an array-like (could be numpy array) of data and the corresponding target values, and performs the optimization of the learnable parameters in the model.  See the documentation for the [fit()](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit) function for more details.\n",
    "\n",
    "Once trained, the model can be used to predict, using the `predict()` function. \n",
    "\n",
    "```python\n",
    "prediction = model.predict(new_data)\n",
    "```\n",
    "  \n",
    "## Tasks\n",
    "Begin by importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i--utUHaFa67",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelchan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gkp-UUKqFa7M"
   },
   "source": [
    "### Understand the dataset\n",
    "\n",
    "Understanding your dataset is the first prerequisit to training any model.  The CIFAR-10 dataset is provided directly from Keras.  \n",
    "- Download the dataset. See [`tf.keras.datasets`](https://keras.io/datasets/) for how to download the data, and what format it is provided.  Note that the dataset is already divided into a training set of 50000 images, and a test set of 10000.\n",
    "- Verify that the shape of the image and target arrays are what you expect.\n",
    "- Create a list of labels corresponding to the 10 categories.  This will be used to convert the 0-9 digits in the target arrays to string labels. The categories are labeled as follows\n",
    "  0. airplane\n",
    "  1. automobile\n",
    "  2. bird\n",
    "  3. cat\n",
    "  4. deer\n",
    "  5. dog\n",
    "  6. frog\n",
    "  7. horse\n",
    "  8. ship\n",
    "  9. truck\n",
    "- Visualize some images in each category using the `imshow()` function in `matplotlib.pyplot`.  Can you recreate the figure at the top?  Hint: the top figure was created using the first 8 images belonging to each category in the training data.\n",
    "- Normalize the image data from [0,255] to be [0,1].  Normalizing improves model training.  (to test this, you can comment out the normalization later)\n",
    "- Lastly, convert the target arrays to one-hot encodings.  Hint: checkout the [`tf.keras.utils.to_categorical()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q552dZBIFa7R"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "def load_cifar_data():\n",
    "    \"\"\"\n",
    "    Loads the CIFAR-10 dataset using Keras and preprocess for training.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    labels = ['airplane','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "    return x_train, y_train, x_test, y_test, labels\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test, labels = load_cifar_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[158 112  49]\n",
      "   [159 111  47]\n",
      "   [165 116  51]\n",
      "   ...\n",
      "   [137  95  36]\n",
      "   [126  91  36]\n",
      "   [116  85  33]]\n",
      "\n",
      "  [[152 112  51]\n",
      "   [151 110  40]\n",
      "   [159 114  45]\n",
      "   ...\n",
      "   [136  95  31]\n",
      "   [125  91  32]\n",
      "   [119  88  34]]\n",
      "\n",
      "  [[151 110  47]\n",
      "   [151 109  33]\n",
      "   [158 111  36]\n",
      "   ...\n",
      "   [139  98  34]\n",
      "   [130  95  34]\n",
      "   [120  89  33]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 68 124 177]\n",
      "   [ 42 100 148]\n",
      "   [ 31  88 137]\n",
      "   ...\n",
      "   [ 38  97 146]\n",
      "   [ 13  64 108]\n",
      "   [ 40  85 127]]\n",
      "\n",
      "  [[ 61 116 168]\n",
      "   [ 49 102 148]\n",
      "   [ 35  85 132]\n",
      "   ...\n",
      "   [ 26  82 130]\n",
      "   [ 29  82 126]\n",
      "   [ 20  64 107]]\n",
      "\n",
      "  [[ 54 107 160]\n",
      "   [ 56 105 149]\n",
      "   [ 45  89 132]\n",
      "   ...\n",
      "   [ 24  77 124]\n",
      "   [ 34  84 129]\n",
      "   [ 21  67 110]]]\n",
      "\n",
      "\n",
      " [[[235 235 235]\n",
      "   [231 231 231]\n",
      "   [232 232 232]\n",
      "   ...\n",
      "   [233 233 233]\n",
      "   [233 233 233]\n",
      "   [232 232 232]]\n",
      "\n",
      "  [[238 238 238]\n",
      "   [235 235 235]\n",
      "   [235 235 235]\n",
      "   ...\n",
      "   [236 236 236]\n",
      "   [236 236 236]\n",
      "   [235 235 235]]\n",
      "\n",
      "  [[237 237 237]\n",
      "   [234 234 234]\n",
      "   [234 234 234]\n",
      "   ...\n",
      "   [235 235 235]\n",
      "   [235 235 235]\n",
      "   [234 234 234]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 87  99  89]\n",
      "   [ 43  51  37]\n",
      "   [ 19  23  11]\n",
      "   ...\n",
      "   [169 184 179]\n",
      "   [182 197 193]\n",
      "   [188 202 201]]\n",
      "\n",
      "  [[ 82  96  82]\n",
      "   [ 46  57  36]\n",
      "   [ 36  44  22]\n",
      "   ...\n",
      "   [174 189 183]\n",
      "   [185 200 196]\n",
      "   [187 202 200]]\n",
      "\n",
      "  [[ 85 101  83]\n",
      "   [ 62  75  48]\n",
      "   [ 58  67  38]\n",
      "   ...\n",
      "   [168 183 178]\n",
      "   [180 195 191]\n",
      "   [186 200 199]]]\n",
      "\n",
      "\n",
      " [[[158 190 222]\n",
      "   [158 187 218]\n",
      "   [139 166 194]\n",
      "   ...\n",
      "   [228 231 234]\n",
      "   [237 239 243]\n",
      "   [238 241 246]]\n",
      "\n",
      "  [[170 200 229]\n",
      "   [172 199 226]\n",
      "   [151 176 201]\n",
      "   ...\n",
      "   [232 232 236]\n",
      "   [246 246 250]\n",
      "   [246 247 251]]\n",
      "\n",
      "  [[174 201 225]\n",
      "   [176 200 222]\n",
      "   [157 179 199]\n",
      "   ...\n",
      "   [230 229 232]\n",
      "   [250 249 251]\n",
      "   [245 244 247]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 31  40  45]\n",
      "   [ 30  39  44]\n",
      "   [ 26  35  40]\n",
      "   ...\n",
      "   [ 37  40  46]\n",
      "   [  9  13  14]\n",
      "   [  4   7   5]]\n",
      "\n",
      "  [[ 23  34  39]\n",
      "   [ 27  38  43]\n",
      "   [ 25  36  41]\n",
      "   ...\n",
      "   [ 19  20  24]\n",
      "   [  4   6   3]\n",
      "   [  5   7   3]]\n",
      "\n",
      "  [[ 28  41  47]\n",
      "   [ 30  43  50]\n",
      "   [ 32  45  52]\n",
      "   ...\n",
      "   [  5   6   8]\n",
      "   [  4   5   3]\n",
      "   [  7   8   7]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 20  15  12]\n",
      "   [ 19  14  11]\n",
      "   [ 15  14  11]\n",
      "   ...\n",
      "   [ 10   9   7]\n",
      "   [ 12  11   9]\n",
      "   [ 13  12  10]]\n",
      "\n",
      "  [[ 21  16  13]\n",
      "   [ 20  16  13]\n",
      "   [ 18  17  12]\n",
      "   ...\n",
      "   [ 10   9   7]\n",
      "   [ 10   9   7]\n",
      "   [ 12  11   9]]\n",
      "\n",
      "  [[ 21  16  13]\n",
      "   [ 21  17  12]\n",
      "   [ 20  18  11]\n",
      "   ...\n",
      "   [ 12  11   9]\n",
      "   [ 12  11   9]\n",
      "   [ 13  12  10]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 33  25  13]\n",
      "   [ 34  26  15]\n",
      "   [ 34  26  15]\n",
      "   ...\n",
      "   [ 28  25  52]\n",
      "   [ 29  25  58]\n",
      "   [ 23  20  42]]\n",
      "\n",
      "  [[ 33  25  14]\n",
      "   [ 34  26  15]\n",
      "   [ 34  26  15]\n",
      "   ...\n",
      "   [ 27  24  52]\n",
      "   [ 27  24  56]\n",
      "   [ 25  22  47]]\n",
      "\n",
      "  [[ 31  23  12]\n",
      "   [ 32  24  13]\n",
      "   [ 33  25  14]\n",
      "   ...\n",
      "   [ 24  23  50]\n",
      "   [ 26  23  53]\n",
      "   [ 25  20  47]]]\n",
      "\n",
      "\n",
      " [[[ 25  40  12]\n",
      "   [ 15  36   3]\n",
      "   [ 23  41  18]\n",
      "   ...\n",
      "   [ 61  82  78]\n",
      "   [ 92 113 112]\n",
      "   [ 75  89  92]]\n",
      "\n",
      "  [[ 12  25   6]\n",
      "   [ 20  37   7]\n",
      "   [ 24  36  15]\n",
      "   ...\n",
      "   [115 134 138]\n",
      "   [149 168 177]\n",
      "   [104 117 131]]\n",
      "\n",
      "  [[ 12  25  11]\n",
      "   [ 15  29   6]\n",
      "   [ 34  40  24]\n",
      "   ...\n",
      "   [154 172 182]\n",
      "   [157 175 192]\n",
      "   [116 129 151]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100 129  81]\n",
      "   [103 132  84]\n",
      "   [104 134  86]\n",
      "   ...\n",
      "   [ 97 128  84]\n",
      "   [ 98 126  84]\n",
      "   [ 91 121  79]]\n",
      "\n",
      "  [[103 132  83]\n",
      "   [104 131  83]\n",
      "   [107 135  87]\n",
      "   ...\n",
      "   [101 132  87]\n",
      "   [ 99 127  84]\n",
      "   [ 92 121  79]]\n",
      "\n",
      "  [[ 95 126  78]\n",
      "   [ 95 123  76]\n",
      "   [101 128  81]\n",
      "   ...\n",
      "   [ 93 124  80]\n",
      "   [ 95 123  81]\n",
      "   [ 92 120  80]]]\n",
      "\n",
      "\n",
      " [[[ 73  78  75]\n",
      "   [ 98 103 113]\n",
      "   [ 99 106 114]\n",
      "   ...\n",
      "   [135 150 152]\n",
      "   [135 149 154]\n",
      "   [203 215 223]]\n",
      "\n",
      "  [[ 69  73  70]\n",
      "   [ 84  89  97]\n",
      "   [ 68  75  81]\n",
      "   ...\n",
      "   [ 85  95  89]\n",
      "   [ 71  82  80]\n",
      "   [120 133 135]]\n",
      "\n",
      "  [[ 69  73  70]\n",
      "   [ 90  95 100]\n",
      "   [ 62  71  74]\n",
      "   ...\n",
      "   [ 74  81  70]\n",
      "   [ 53  62  54]\n",
      "   [ 62  74  69]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[123 128  96]\n",
      "   [132 132 102]\n",
      "   [129 128 100]\n",
      "   ...\n",
      "   [108 107  88]\n",
      "   [ 62  60  55]\n",
      "   [ 27  27  28]]\n",
      "\n",
      "  [[115 121  91]\n",
      "   [123 124  95]\n",
      "   [129 126  99]\n",
      "   ...\n",
      "   [115 116  94]\n",
      "   [ 66  65  59]\n",
      "   [ 27  27  27]]\n",
      "\n",
      "  [[116 120  90]\n",
      "   [121 122  94]\n",
      "   [129 128 101]\n",
      "   ...\n",
      "   [116 115  94]\n",
      "   [ 68  65  58]\n",
      "   [ 27  26  26]]]]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the dataset\n",
    "# TODO\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4atIU69TFa7a"
   },
   "source": [
    "### First naive model\n",
    "\n",
    "In order to better understand the importance of CNNs, it is instructive to first see how well a naive dense network performs on the dataset.\n",
    "\n",
    "- Create a sequential model with 4 `Dense` hidden layers of 2048, 1024, 512, and 256 nodes each, with ReLU activation, and a linear output layer of 10 nodes.  Note that you will need to use the `Flatten` layer first in order to convert the 3D (x, y, rgb) image data into 1D.\n",
    "- Compute by hand the total number of trainable parameters (weights and biases) in the model.\n",
    "- Compile the model with a `categorical_crossentropy` loss, using the SGD optimizer, including the `accuracy` metric.\n",
    "- Use the `summary()` function on model to get a text summary of the model.  Did you compute the number of parameters correctly?\n",
    "- Train the model:\n",
    "  - Start with small batch size of 32 and train for 10 epochs\n",
    "  - Use early stopping on the validation accuracy with a patience of 2\n",
    "- How does the model perform? Is it any better than a random guess? \n",
    "- Try changing the batch size to see if there is any improvement.\n",
    "- Try adding batch normalization after each hidden layer.  Any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "t0GIv98tFa7d"
   },
   "outputs": [],
   "source": [
    "def dense_model(input_shape, num_classes):\n",
    "    model =  #TODO\n",
    "    model.compile() #TODO \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, x, y, x_test, y_test, batch_size=128, epochs=10):\n",
    "    # TODO\n",
    "    \n",
    "\n",
    "model = dense_model(x_train.shape[1:], 10)\n",
    "train_model(model, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3oILsxfFa7k"
   },
   "source": [
    "### Convolutional Net\n",
    "\n",
    "Convolutional neural networks allow us to do drastically better on this dataset (and many image classification problems in general).  In this task, you will build your first convolutional network and see how it performs during training.\n",
    "\n",
    "- Create a new model with the following layers\n",
    "  - 3x3 2D convolution with zero padding (same), 32 filters\n",
    "  - ReLU activation\n",
    "  - 3,3 2D convolution, no padding, 32 filters\n",
    "  - ReLU activation\n",
    "  - Max pooling with size (2,2)\n",
    "  - 3x3 2D convolution, no padding, 64 filters\n",
    "  - ReLU activation\n",
    "  - 3x3 2D convolution, no padding, 64 filters\n",
    "  - ReLU activation\n",
    "  - Max pooling with size (2,2)\n",
    "  - Flatten\n",
    "  - Dense layer with 512 nodes, ReLU activation\n",
    "  - Softmax output layer with 10 nodes\n",
    "- Compile the network with same optimizer and metrics as the dense network.\n",
    "- Compute by hand the number of trainable parameters in this network.  Are there more or less than the more simple dense network?  Why?  Confirm with `summary()`.\n",
    "- Use the same training procedure as before for 10 epochs and batch size of 32.\n",
    "- How does the validation accuracy change with each epoch?\n",
    "- Increase the batch size to 64 and retrain.  Better or worse?  Try 128 as well.  How does increasin the batch size improve the training?\n",
    "- Note how the validation accuracy begins to decrease at some point, while the training accuracy continues to increase.  What is this phenomena called?  Try adding 3 dropout layers to the model, one before each max pooling layer and one before the last layer, using a dropout ratio of 0.25.  Does this improve over-fitting?\n",
    "- Play with batch normalization.  For example, add batch normalization layers after each dropout layer.  Do you notice a faster increase in the model improvement? Why?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zo-kx5KcFa7l"
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, num_classes):\n",
    "    # TODO\n",
    "    return model\n",
    "\n",
    "# Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVAiCTotFa7r"
   },
   "source": [
    "### Make some predictions\n",
    "\n",
    "Assuming all went well during the previous tasks, you can now predict the category of a new image!  Here are a few examples of my predictions:\n",
    "\n",
    "![predictions.png](attachment:predictions.png)\n",
    "\n",
    "- Use `predict` on your trained model to test its prediction on a few example images.  You can use images taken from the test dataset, as these were not used to train your model.  Hint: at this point, it is probably convenient to use the `save` and `load_model` functions from Keras.  You can save the model after training it, and then decide to load from saved file instead of building a new one (if available) on successive runs.\n",
    "- Using `imshow` and `hbar` from `matplotlib.pyplot`, try to recreate the image above for a few example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8req4JpDFa7s"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf5IDVhSFa7w"
   },
   "source": [
    "- Create a _confusion matrix_. A confusion matrix is often used in supervised learning to understand how well (or not) each category is being classified.  Each element (i,j) in the confusion matrix represents the predicted class j for each true class i.  Consider the following 10 predictions for a 2 category model predicting male or female.\n",
    "\n",
    "| example     | true category  | predicted category  |\n",
    "|-------------|----------------|---------------------|\n",
    "| 1           | male           | male                |\n",
    "| 2           | female         | male                |\n",
    "| 3           | female         | female              |\n",
    "| 4           | male           | male                |\n",
    "| 5           | male           | female              |\n",
    "| 6           | male           | male                |\n",
    "| 7           | female         | female              |\n",
    "| 8           | male           | female              |\n",
    "| 9           | female         | female              |\n",
    "| 10          | female         | female              |\n",
    "\n",
    "Based on the above data, the model is accurate 70% of the time.  The confusion matrix is\n",
    "\n",
    "|        | male | female |\n",
    "|--------|------|--------|\n",
    "| male   | 3    | 2      |\n",
    "| female | 1    | 4      |\n",
    "\n",
    "The confusion matrix gives us more information than a simple accuracy measurement.  In this case, we see that the class female has a higher accuracy over male.  Create the confusion matrix the CIFAR-10 dataset using the test data.  What does it tell you about the relationships between each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IbtLQvynFa7y"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1cTqrGtFa73"
   },
   "source": [
    "## Further exercises \n",
    "\n",
    "- Try training on additional datasets available with Keras.  For example, the MNIST data (hand-written digits) will require virtually no code changes to solve.\n",
    "- Play with different CNN architectures.  Can you beat the performance of the net used in this lab?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab8.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
